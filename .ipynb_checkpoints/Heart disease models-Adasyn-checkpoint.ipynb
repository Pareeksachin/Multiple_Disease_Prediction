{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7deb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import cross_val_score,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d81a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart = pd.read_csv(\"heart_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16937404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef49f2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.Sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ee8dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97644ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col = heart.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d41920",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col.drop(['HeartDisease'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "623cbfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cols= list(object_col.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c1e8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smoking',\n",
       " 'AlcoholDrinking',\n",
       " 'Stroke',\n",
       " 'DiffWalking',\n",
       " 'Sex',\n",
       " 'AgeCategory',\n",
       " 'Race',\n",
       " 'Diabetic',\n",
       " 'PhysicalActivity',\n",
       " 'GenHealth',\n",
       " 'Asthma',\n",
       " 'KidneyDisease',\n",
       " 'SkinCancer']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a91bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_test(df, column1, column2, significance_level=0.05):\n",
    "    \n",
    "    contingency_table = pd.crosstab(df[column1], df[column2])\n",
    "    \n",
    "    chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    h0_status = True if p_value <= significance_level else False\n",
    "\n",
    "    return {'p_value': p_value, 'h0_rejected': h0_status}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f85e894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h0_rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Smoking</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalking</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeCategory</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetic</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHealth</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asthma</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KidneyDisease</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinCancer</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  h0_rejected\n",
       "Smoking                  True\n",
       "AlcoholDrinking          True\n",
       "Stroke                   True\n",
       "DiffWalking              True\n",
       "Sex                      True\n",
       "AgeCategory              True\n",
       "Race                     True\n",
       "Diabetic                 True\n",
       "PhysicalActivity         True\n",
       "GenHealth                True\n",
       "Asthma                   True\n",
       "KidneyDisease            True\n",
       "SkinCancer               True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chi2_results = {}\n",
    "\n",
    "for col in compare_cols:\n",
    "    chi2_results[col] = chi2_test(heart, 'HeartDisease', col)['h0_rejected']\n",
    "    \n",
    "chi2_results = pd.DataFrame(chi2_results, index=['h0_rejected']).T\n",
    "\n",
    "display(chi2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a7668b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95f81c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_dum = pd.get_dummies(heart)\n",
    "heart_dum.drop('HeartDisease_No',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "553e53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train ,Final_test = train_test_split(heart_dum,test_size=0.15,stratify=heart_dum['HeartDisease_Yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64b54717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263509, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aedbdfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop('HeartDisease_Yes',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e4767c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['HeartDisease_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee1560ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartDisease_Yes\n",
       "False    82.603251\n",
       "True     17.396749\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['HeartDisease_Yes'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad8e51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc100ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='HeartDisease_Yes', ylabel='Count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a3361ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE,ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a43f174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote= ADASYN(random_state=23,n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ac7d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y = smote.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f3f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s#mote_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "384993be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote_x.drop('HeartDisease_No',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77246758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote_x.shape#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cdac43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "666084b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c032e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s#ns.histplot(smote_y.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9a235c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = Final_test.drop('HeartDisease_Yes',axis=1)\n",
    "y_test = Final_test['HeartDisease_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7183f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score , confusion_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4bc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b74317fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d678cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80a736",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e04e8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87f80257",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {'C':np.linspace(0.01,5,10),'l1_ratio':np.linspace(0,1,10),'penalty':['l1','l2','elasticnet',None]}\n",
    "kfold = StratifiedKFold(n_splits=3,shuffle=True,random_state=23)\n",
    "gcv_lr = GridSearchCV(lr,param_grid=lr_params,cv=kfold,scoring='neg_log_loss',verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ace1a2",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5094a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC()\n",
    "#scaler = StandardScaler()\n",
    "#p#ipe_svm = Pipeline([('SCL',scaler),('SVM',svm)])\n",
    "#pipe_svm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c62f37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_params = {'SVM__kernel':['linear','rbf','poly'],'SVM__probability':True,'SVM__C':np.linspace(0.01,5,10),'SVM__degree':[2,3],'SVM__gamma':np.linspace(0.001,10,10)}\n",
    "#gcv_svm = GridSearchCV(pipe_svm,param_grid=svm_params,cv=kfold,scoring='neg_log_loss',verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc9d80",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca44c7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b36be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_params = {'max_depth':[None,3,4,5,6,7],'min_samples_split':[2,5,10,20],'min_samples_leaf':[1,5,10,20]}\n",
    "gcv_dtc = GridSearchCV(dtc,param_grid=dtc_params,cv=kfold,scoring='neg_log_loss',verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ba621",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "801892d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55ed7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'max_depth':[None,3,4],'max_features':[5,10,15,20],'n_estimators':[100,200,300,400]}\n",
    "gcv_rf = GridSearchCV(rf,param_grid=rf_params,cv=kfold,scoring='neg_log_loss',verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa71e88",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33d66c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': None,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d912016",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'learning_rate':np.linspace(0.001,0.5,5),'max_depth':[None,2,5],'n_estimators':[200,300]}\n",
    "gcv_xgb = GridSearchCV(xgb,param_grid=xgb_params,cv=kfold,scoring='neg_log_loss',verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854dd1e6",
   "metadata": {},
   "source": [
    "# Logistic regression fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7799cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .C=0.01, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 2/3] END C=0.01, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   6.7s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   5.7s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.8s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   7.5s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.5s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 3/3] END .C=0.01, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.7s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   5.8s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.8s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.4s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   5.8s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.9s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   7.4s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .C=0.01, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.5s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   5.8s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.8s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   6.4s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   7.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.6s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   5.8s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.4s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   5.9s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   5.8s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   7.6s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   5.7s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   7.0s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   6.4s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   7.9s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   7.8s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.6s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.5s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   5.9s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   7.2s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   7.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   5.8s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   7.9s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 1/3] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .C=0.01, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   5.9s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   5.6s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   5.6s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   5.8s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 1/3] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   7.6s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.8s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "600 fits failed out of a total of 1200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [        nan -0.37081187         nan -0.37073885         nan -0.37081187\n",
      "         nan -0.37073885         nan -0.37081187         nan -0.37073885\n",
      "         nan -0.37081187         nan -0.37073885         nan -0.37081187\n",
      "         nan -0.37073885         nan -0.37081187         nan -0.37073885\n",
      "         nan -0.37081187         nan -0.37073885         nan -0.37081187\n",
      "         nan -0.37073885         nan -0.37081187         nan -0.37073885\n",
      "         nan -0.37081187         nan -0.37073885         nan -0.3706228\n",
      "         nan -0.37073885         nan -0.3706228          nan -0.37073885\n",
      "         nan -0.3706228          nan -0.37073885         nan -0.3706228\n",
      "         nan -0.37073885         nan -0.3706228          nan -0.37073885\n",
      "         nan -0.3706228          nan -0.37073885         nan -0.3706228\n",
      "         nan -0.37073885         nan -0.3706228          nan -0.37073885\n",
      "         nan -0.3706228          nan -0.37073885         nan -0.3706228\n",
      "         nan -0.37073885         nan -0.37062036         nan -0.37073885\n",
      "         nan -0.37062036         nan -0.37073885         nan -0.37062036\n",
      "         nan -0.37073885         nan -0.37062036         nan -0.37073885\n",
      "         nan -0.37062036         nan -0.37073885         nan -0.37062036\n",
      "         nan -0.37073885         nan -0.37062036         nan -0.37073885\n",
      "         nan -0.37062036         nan -0.37073885         nan -0.37062036\n",
      "         nan -0.37073885         nan -0.37062036         nan -0.37073885\n",
      "         nan -0.37066978         nan -0.37073885         nan -0.37066978\n",
      "         nan -0.37073885         nan -0.37066978         nan -0.37073885\n",
      "         nan -0.37066978         nan -0.37073885         nan -0.37066978\n",
      "         nan -0.37073885         nan -0.37066978         nan -0.37073885\n",
      "         nan -0.37066978         nan -0.37073885         nan -0.37066978\n",
      "         nan -0.37073885         nan -0.37066978         nan -0.37073885\n",
      "         nan -0.37066978         nan -0.37073885         nan -0.3706818\n",
      "         nan -0.37073885         nan -0.3706818          nan -0.37073885\n",
      "         nan -0.3706818          nan -0.37073885         nan -0.3706818\n",
      "         nan -0.37073885         nan -0.3706818          nan -0.37073885\n",
      "         nan -0.3706818          nan -0.37073885         nan -0.3706818\n",
      "         nan -0.37073885         nan -0.3706818          nan -0.37073885\n",
      "         nan -0.3706818          nan -0.37073885         nan -0.3706818\n",
      "         nan -0.37073885         nan -0.37060225         nan -0.37073885\n",
      "         nan -0.37060225         nan -0.37073885         nan -0.37060225\n",
      "         nan -0.37073885         nan -0.37060225         nan -0.37073885\n",
      "         nan -0.37060225         nan -0.37073885         nan -0.37060225\n",
      "         nan -0.37073885         nan -0.37060225         nan -0.37073885\n",
      "         nan -0.37060225         nan -0.37073885         nan -0.37060225\n",
      "         nan -0.37073885         nan -0.37060225         nan -0.37073885\n",
      "         nan -0.37069809         nan -0.37073885         nan -0.37069809\n",
      "         nan -0.37073885         nan -0.37069809         nan -0.37073885\n",
      "         nan -0.37069809         nan -0.37073885         nan -0.37069809\n",
      "         nan -0.37073885         nan -0.37069809         nan -0.37073885\n",
      "         nan -0.37069809         nan -0.37073885         nan -0.37069809\n",
      "         nan -0.37073885         nan -0.37069809         nan -0.37073885\n",
      "         nan -0.37069809         nan -0.37073885         nan -0.37068222\n",
      "         nan -0.37073885         nan -0.37068222         nan -0.37073885\n",
      "         nan -0.37068222         nan -0.37073885         nan -0.37068222\n",
      "         nan -0.37073885         nan -0.37068222         nan -0.37073885\n",
      "         nan -0.37068222         nan -0.37073885         nan -0.37068222\n",
      "         nan -0.37073885         nan -0.37068222         nan -0.37073885\n",
      "         nan -0.37068222         nan -0.37073885         nan -0.37068222\n",
      "         nan -0.37073885         nan -0.3706491          nan -0.37073885\n",
      "         nan -0.3706491          nan -0.37073885         nan -0.3706491\n",
      "         nan -0.37073885         nan -0.3706491          nan -0.37073885\n",
      "         nan -0.3706491          nan -0.37073885         nan -0.3706491\n",
      "         nan -0.37073885         nan -0.3706491          nan -0.37073885\n",
      "         nan -0.3706491          nan -0.37073885         nan -0.3706491\n",
      "         nan -0.37073885         nan -0.3706491          nan -0.37073885\n",
      "         nan -0.37067046         nan -0.37073885         nan -0.37067046\n",
      "         nan -0.37073885         nan -0.37067046         nan -0.37073885\n",
      "         nan -0.37067046         nan -0.37073885         nan -0.37067046\n",
      "         nan -0.37073885         nan -0.37067046         nan -0.37073885\n",
      "         nan -0.37067046         nan -0.37073885         nan -0.37067046\n",
      "         nan -0.37073885         nan -0.37067046         nan -0.37073885\n",
      "         nan -0.37067046         nan -0.37073885]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([0.01      , 0.56444444, 1.11888889, 1.67333333, 2.22777778,\n",
       "       2.78222222, 3.33666667, 3.89111111, 4.44555556, 5.        ]),\n",
       "                         &#x27;l1_ratio&#x27;: array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([0.01      , 0.56444444, 1.11888889, 1.67333333, 2.22777778,\n",
       "       2.78222222, 3.33666667, 3.89111111, 4.44555556, 5.        ]),\n",
       "                         &#x27;l1_ratio&#x27;: array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([0.01      , 0.56444444, 1.11888889, 1.67333333, 2.22777778,\n",
       "       2.78222222, 3.33666667, 3.89111111, 4.44555556, 5.        ]),\n",
       "                         'l1_ratio': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv_lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d02d0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2.7822222222222224, 'l1_ratio': 0.0, 'penalty': 'l2'} -0.3706022512439405\n"
     ]
    }
   ],
   "source": [
    "print(gcv_lr.best_params_,gcv_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca549687",
   "metadata": {},
   "source": [
    "# SVM fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9db7007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gcv_svm.fit(smote_x,smote_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f08f29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(gcv_svm.best_params_,gcv_svm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364073f",
   "metadata": {},
   "source": [
    "# Decision Tree fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ceeb4adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 2/3] END .C=0.01, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.7s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   7.2s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   7.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.7s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.5s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   5.8s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.5s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   6.4s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.8s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.5s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   5.6s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=-5.283 total time=   3.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END ....C=0.01, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END ....C=0.01, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END ....C=0.01, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.9s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   5.7s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   7.3s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.4s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   6.4s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   5.8s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   6.3s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   6.8s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 1/3] END C=5.0, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   3.3s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=5, min_samples_split=2;, score=-2.283 total time=   2.9s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=10, min_samples_split=2;, score=-1.244 total time=   2.8s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=10, min_samples_split=20;, score=-1.293 total time=   2.9s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=1, min_samples_split=10;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=5, min_samples_split=20;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   5.7s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   7.3s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   5.8s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   5.7s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   5.8s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=-3.710 total time=   3.0s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=10, min_samples_split=2;, score=-1.331 total time=   2.8s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=20, min_samples_split=2;, score=-0.751 total time=   2.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=1, min_samples_split=5;, score=-0.399 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=5, min_samples_split=10;, score=-0.400 total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   7.4s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   5.8s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   5.9s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   5.7s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.5s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.5s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   7.7s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   7.5s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   5.6s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   5.7s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=-6.890 total time=   3.1s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=10, min_samples_split=5;, score=-1.246 total time=   2.8s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=20, min_samples_split=2;, score=-0.761 total time=   2.8s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=1, min_samples_split=10;, score=-0.399 total time=   0.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=5, min_samples_split=20;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=20, min_samples_split=2;, score=-0.399 total time=   0.7s\n",
      "[CV 1/3] END ....C=0.01, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.5s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.4s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   6.6s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   4.5s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=1, min_samples_split=20;, score=-2.259 total time=   2.9s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=5, min_samples_split=10;, score=-2.322 total time=   2.9s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=10, min_samples_split=20;, score=-1.244 total time=   2.8s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=1, min_samples_split=5;, score=-0.399 total time=   0.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=5, min_samples_split=10;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=10, min_samples_split=20;, score=-0.399 total time=   0.7s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=1, min_samples_split=2;, score=-0.389 total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.5s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   6.4s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.4s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   6.3s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   4.8s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=-3.657 total time=   3.1s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=10, min_samples_split=10;, score=-1.248 total time=   2.8s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=20, min_samples_split=20;, score=-0.720 total time=   3.2s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=5, min_samples_split=5;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=10, min_samples_split=10;, score=-0.399 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=20, min_samples_split=20;, score=-0.400 total time=   0.7s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=5, min_samples_split=5;, score=-0.389 total time=   1.0s\n",
      "[CV 3/3] END ....C=0.01, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.6s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   5.6s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   6.4s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.9s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   7.3s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   6.7s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   6.3s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   7.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   4.5s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=1, min_samples_split=20;, score=-2.313 total time=   3.0s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=10, min_samples_split=2;, score=-1.287 total time=   2.9s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=20, min_samples_split=5;, score=-0.758 total time=   2.8s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=1, min_samples_split=20;, score=-0.399 total time=   0.8s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=10, min_samples_split=5;, score=-0.399 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=20, min_samples_split=10;, score=-0.400 total time=   0.7s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=1, min_samples_split=20;, score=-0.389 total time=   0.9s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=10, min_samples_split=2;, score=-0.389 total time=   1.1s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=20, min_samples_split=20;, score=-0.389 total time=   0.9s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=1, min_samples_split=20;, score=-0.380 total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.5s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.9s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.8s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   5.8s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   5.8s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.6s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   7.2s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.4s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   7.2s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=-7.089 total time=   3.1s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=5, min_samples_split=20;, score=-1.641 total time=   2.8s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=10, min_samples_split=10;, score=-1.324 total time=   2.8s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=1, min_samples_split=2;, score=-0.400 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=5, min_samples_split=5;, score=-0.400 total time=   0.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=10, min_samples_split=20;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=1, min_samples_split=2;, score=-0.387 total time=   0.9s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=5, min_samples_split=10;, score=-0.389 total time=   0.9s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=10, min_samples_split=20;, score=-0.387 total time=   0.9s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=-0.380 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=5, min_samples_split=5;, score=-0.381 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=10, min_samples_split=20;, score=-0.380 total time=   1.1s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=1, min_samples_split=2;, score=-0.377 total time=   1.2s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=5, min_samples_split=5;, score=-0.377 total time=   1.2s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=0.01, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=0.01, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   6.2s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   7.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.0, penalty=None;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.3333333333333333, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.6s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   7.3s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   5.8s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.2222222222222222, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=3.8911111111111114, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.0, penalty=None;, score=-0.370 total time=   6.3s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   8.1s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=-6.931 total time=   3.0s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=5, min_samples_split=5;, score=-2.290 total time=   3.0s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=20, min_samples_split=2;, score=-0.720 total time=   2.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=1, min_samples_split=2;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=5, min_samples_split=5;, score=-0.399 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=10, min_samples_split=10;, score=-0.400 total time=   0.7s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=1, min_samples_split=2;, score=-0.389 total time=   0.9s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=5, min_samples_split=5;, score=-0.387 total time=   0.9s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=10, min_samples_split=10;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=-0.380 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=5, min_samples_split=10;, score=-0.380 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=10, min_samples_split=20;, score=-0.380 total time=   1.1s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=1, min_samples_split=2;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=5, min_samples_split=5;, score=-0.376 total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=0.01, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=0.01, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   7.0s\n",
      "[CV 1/3] END .C=0.01, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   5.9s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.1111111111111111, penalty=None;, score=-0.370 total time=   5.9s\n",
      "[CV 3/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=0.5644444444444445, l1_ratio=0.6666666666666666, penalty=None;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=0.5644444444444445, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.6s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.118888888888889, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=1.118888888888889, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=1.118888888888889, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=0.0, penalty=l2;, score=-0.370 total time=   6.4s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   6.3s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   7.4s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=1.6733333333333336, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   6.5s\n",
      "[CV 2/3] END C=2.227777777777778, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=2.227777777777778, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   5.8s\n",
      "[CV 1/3] END C=2.227777777777778, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   6.6s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.2222222222222222, penalty=None;, score=-0.371 total time=   7.2s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=2.7822222222222224, l1_ratio=0.5555555555555556, penalty=None;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=2.7822222222222224, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.370 total time=   6.0s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=0.3333333333333333, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=3.336666666666667, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=3.336666666666667, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=3.336666666666667, l1_ratio=1.0, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END C=3.8911111111111114, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=3.8911111111111114, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.371 total time=   5.7s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=4.445555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.2s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.370 total time=   6.3s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 1/3] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.370 total time=   3.7s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=5, min_samples_split=5;, score=-2.324 total time=   3.3s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=10, min_samples_split=10;, score=-1.291 total time=   2.9s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=20, min_samples_split=20;, score=-0.760 total time=   2.8s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=5, min_samples_split=2;, score=-0.399 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=10, min_samples_split=5;, score=-0.400 total time=   0.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=20, min_samples_split=20;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=5, min_samples_split=2;, score=-0.387 total time=   0.9s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=10, min_samples_split=5;, score=-0.389 total time=   0.9s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=20, min_samples_split=10;, score=-0.389 total time=   0.9s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=1, min_samples_split=20;, score=-0.381 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=10, min_samples_split=5;, score=-0.380 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=20, min_samples_split=10;, score=-0.381 total time=   1.1s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=5, min_samples_split=2;, score=-0.376 total time=   1.2s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=10, min_samples_split=5;, score=-0.376 total time=   1.3s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=20, min_samples_split=10;, score=-0.377 total time=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 3, 4, 5, 6, 7],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10, 20],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10, 20]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 3, 4, 5, 6, 7],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10, 20],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10, 20]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 3, 4, 5, 6, 7],\n",
       "                         'min_samples_leaf': [1, 5, 10, 20],\n",
       "                         'min_samples_split': [2, 5, 10, 20]},\n",
       "             scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv_dtc.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aae0403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_samples_leaf': 20, 'min_samples_split': 2} -0.37160115267202354\n"
     ]
    }
   ],
   "source": [
    "print(gcv_dtc.best_params_,gcv_dtc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9511856a",
   "metadata": {},
   "source": [
    "# Random Forest fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d073ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=10, min_samples_split=2;, score=-0.380 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=20, min_samples_split=5;, score=-0.381 total time=   1.1s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=1, min_samples_split=20;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=10, min_samples_split=2;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=20, min_samples_split=5;, score=-0.376 total time=   1.2s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=1, min_samples_split=10;, score=-0.375 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=5, min_samples_split=20;, score=-0.374 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=20, min_samples_split=2;, score=-0.372 total time=   1.4s\n",
      "[CV 3/3] END max_depth=None, max_features=5, n_estimators=300;, score=-0.455 total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END max_depth=3, min_samples_leaf=20, min_samples_split=2;, score=-0.400 total time=   0.7s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=1, min_samples_split=5;, score=-0.389 total time=   0.9s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=5, min_samples_split=20;, score=-0.387 total time=   0.9s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=20, min_samples_split=2;, score=-0.389 total time=   0.9s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=-0.380 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=5, min_samples_split=20;, score=-0.380 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=20, min_samples_split=2;, score=-0.380 total time=   1.1s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=1, min_samples_split=5;, score=-0.377 total time=   1.2s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=5, min_samples_split=10;, score=-0.377 total time=   1.2s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=20, min_samples_split=2;, score=-0.376 total time=   1.2s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=1, min_samples_split=5;, score=-0.376 total time=   1.7s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=10, min_samples_split=2;, score=-0.371 total time=   1.4s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=20, min_samples_split=5;, score=-0.371 total time=   1.3s\n",
      "[CV 1/3] END max_depth=None, max_features=5, n_estimators=300;, score=-0.448 total time= 2.6min\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.370 total time=   6.2s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.371 total time=   5.3s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=1, min_samples_split=20;, score=-2.278 total time=   3.0s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=10, min_samples_split=5;, score=-1.281 total time=   2.9s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=20, min_samples_split=10;, score=-0.749 total time=   2.8s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=5, min_samples_split=2;, score=-0.399 total time=   0.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=10, min_samples_split=5;, score=-0.399 total time=   0.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=20, min_samples_split=10;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=1, min_samples_split=20;, score=-0.387 total time=   0.9s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=10, min_samples_split=2;, score=-0.387 total time=   0.9s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=20, min_samples_split=5;, score=-0.389 total time=   1.0s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=-0.381 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=10, min_samples_split=2;, score=-0.380 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=20, min_samples_split=5;, score=-0.380 total time=   1.1s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=1, min_samples_split=10;, score=-0.377 total time=   1.2s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=10, min_samples_split=2;, score=-0.376 total time=   1.4s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=20, min_samples_split=10;, score=-0.376 total time=   1.2s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=1, min_samples_split=20;, score=-0.374 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=10, min_samples_split=2;, score=-0.372 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=20, min_samples_split=5;, score=-0.372 total time=   1.2s\n",
      "[CV 2/3] END max_depth=None, max_features=5, n_estimators=300;, score=-0.459 total time= 2.8min\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=10, min_samples_split=5;, score=-1.328 total time=   2.8s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=20, min_samples_split=10;, score=-0.759 total time=   2.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=1, min_samples_split=20;, score=-0.400 total time=   0.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=10, min_samples_split=2;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=20, min_samples_split=5;, score=-0.399 total time=   0.7s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=1, min_samples_split=10;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=5, min_samples_split=20;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=20, min_samples_split=2;, score=-0.389 total time=   0.9s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=-0.380 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=5, min_samples_split=20;, score=-0.380 total time=   1.0s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=20, min_samples_split=2;, score=-0.380 total time=   1.0s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=1, min_samples_split=5;, score=-0.376 total time=   1.2s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=5, min_samples_split=10;, score=-0.376 total time=   1.2s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=10, min_samples_split=10;, score=-0.377 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=1, min_samples_split=5;, score=-0.374 total time=   1.4s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=5, min_samples_split=10;, score=-0.373 total time=   1.7s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=20, min_samples_split=5;, score=-0.372 total time=   1.4s\n",
      "[CV 2/3] END max_depth=None, max_features=5, n_estimators=400;, score=-0.440 total time= 3.4min\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=20, min_samples_split=2;, score=-0.399 total time=   0.8s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=1, min_samples_split=10;, score=-0.389 total time=   1.1s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=10, min_samples_split=5;, score=-0.389 total time=   1.0s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=20, min_samples_split=10;, score=-0.387 total time=   1.0s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=5, min_samples_split=2;, score=-0.380 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=10, min_samples_split=5;, score=-0.380 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=20, min_samples_split=10;, score=-0.380 total time=   1.1s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=1, min_samples_split=20;, score=-0.377 total time=   1.2s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=10, min_samples_split=5;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=20, min_samples_split=10;, score=-0.376 total time=   1.2s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=1, min_samples_split=20;, score=-0.376 total time=   1.4s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=10, min_samples_split=5;, score=-0.371 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=20, min_samples_split=10;, score=-0.372 total time=   1.2s\n",
      "[CV 1/3] END max_depth=None, max_features=5, n_estimators=400;, score=-0.437 total time= 3.6min\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=10, min_samples_split=20;, score=-0.376 total time=   1.3s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=1, min_samples_split=2;, score=-0.376 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=5, min_samples_split=10;, score=-0.373 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=10, min_samples_split=20;, score=-0.372 total time=   1.4s\n",
      "[CV 3/3] END max_depth=None, max_features=5, n_estimators=100;, score=-0.536 total time=  51.9s\n",
      "[CV 3/3] END max_depth=None, max_features=10, n_estimators=200;, score=-0.459 total time= 2.5min\n",
      "[CV 3/3] END max_depth=None, max_features=15, n_estimators=200;, score=-0.438 total time= 3.3min\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=5, min_samples_split=5;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=10, min_samples_split=20;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=-0.380 total time=   1.0s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=5, min_samples_split=5;, score=-0.380 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=10, min_samples_split=10;, score=-0.381 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=20, min_samples_split=20;, score=-0.381 total time=   1.1s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=5, min_samples_split=5;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=10, min_samples_split=10;, score=-0.376 total time=   1.3s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=20, min_samples_split=20;, score=-0.377 total time=   1.2s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=5, min_samples_split=5;, score=-0.373 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=10, min_samples_split=10;, score=-0.372 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=20, min_samples_split=20;, score=-0.372 total time=   1.0s\n",
      "[CV 1/3] END max_depth=None, max_features=10, n_estimators=200;, score=-0.451 total time= 2.4min\n",
      "[CV 2/3] END max_depth=None, max_features=15, n_estimators=100;, score=-0.499 total time= 1.6min\n",
      "[CV 3/3] END max_depth=None, max_features=15, n_estimators=400;, score=-0.406 total time= 6.5min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 3, 4],\n",
       "                         &#x27;max_features&#x27;: [5, 10, 15, 20],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 3, 4],\n",
       "                         &#x27;max_features&#x27;: [5, 10, 15, 20],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 3, 4],\n",
       "                         'max_features': [5, 10, 15, 20],\n",
       "                         'n_estimators': [100, 200, 300, 400]},\n",
       "             scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv_rf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a123df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'max_features': 20, 'n_estimators': 400} -0.3823915741626547\n"
     ]
    }
   ],
   "source": [
    "print(gcv_rf.best_params_,gcv_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65082159",
   "metadata": {},
   "source": [
    "# XGBoost fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c52b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_typ...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: array([0.001  , 0.12575, 0.2505 , 0.37525, 0.5    ]),\n",
       "                         &#x27;max_depth&#x27;: [None, 2, 5],\n",
       "                         &#x27;n_estimators&#x27;: [200, 300]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_typ...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: array([0.001  , 0.12575, 0.2505 , 0.37525, 0.5    ]),\n",
       "                         &#x27;max_depth&#x27;: [None, 2, 5],\n",
       "                         &#x27;n_estimators&#x27;: [200, 300]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=23, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_typ...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': array([0.001  , 0.12575, 0.2505 , 0.37525, 0.5    ]),\n",
       "                         'max_depth': [None, 2, 5],\n",
       "                         'n_estimators': [200, 300]},\n",
       "             scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv_xgb.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a807ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.37525, 'max_depth': 5, 'n_estimators': 300} -0.28219152893554894\n"
     ]
    }
   ],
   "source": [
    "print(gcv_xgb.best_params_,gcv_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f3b5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv_dtc_best = gcv_dtc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "442d4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = Final_test.drop(['HeartDisease_Yes'],axis=1)\n",
    "test_y = Final_test['HeartDisease_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ba1ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b133620",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gcv_dtc_best.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5be1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d993a784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46502, 39)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "963a0abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8325878456840566"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3958477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gcv_lr = gcv_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc99f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gcv_rf = gcv_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f1d10ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gcv_xgb = gcv_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a38e920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8321147477527848"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_gcv_lr.predict(test_x)\n",
    "accuracy_score(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b054bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8273407595372242"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_gcv_rf.predict(test_x)\n",
    "accuracy_score(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea43cdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8863704786890887"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_gcv_xgb.predict(test_x)\n",
    "accuracy_score(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbc0bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(classifier):\n",
    "    classifier.fit(x,y)\n",
    "    prediction=classifier.predict(x_test)\n",
    "    print(\"Log Loss: \",(log_loss(y_test,classifier.predict_proba(x_test)[:,1])))\n",
    "    print(\"Accuracy Score : \",'{0:.2%}'.format(accuracy_score(y_test,prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "703bef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_lr = LogisticRegression(random_state = 0,C=10,penalty= 'l2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "581bf66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  0.3706623076301296\n",
      "Accuracy Score :  83.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcap/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model(classifier_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b88d99a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31e13ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END max_depth=None, max_features=15, n_estimators=400;, score=-0.410 total time= 6.5min\n",
      "[CV 1/3] END max_depth=3, max_features=15, n_estimators=100;, score=-0.394 total time=  21.8s\n",
      "[CV 3/3] END max_depth=3, max_features=15, n_estimators=200;, score=-0.394 total time=  42.1s\n",
      "[CV 3/3] END max_depth=3, max_features=20, n_estimators=100;, score=-0.392 total time=  26.0s\n",
      "[CV 2/3] END max_depth=3, max_features=20, n_estimators=300;, score=-0.391 total time= 1.4min\n",
      "[CV 3/3] END max_depth=4, max_features=5, n_estimators=400;, score=-0.398 total time=  56.5s\n",
      "[CV 3/3] END max_depth=4, max_features=15, n_estimators=100;, score=-0.385 total time=  27.6s\n",
      "[CV 1/3] END max_depth=4, max_features=20, n_estimators=100;, score=-0.383 total time=  33.3s\n",
      "[CV 3/3] END max_depth=4, max_features=20, n_estimators=300;, score=-0.383 total time= 1.3min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=300;, score=-0.583 total time= 1.3min\n",
      "[CV 2/3] END learning_rate=0.12575, max_depth=None, n_estimators=200;, score=-0.292 total time= 2.5min\n",
      "[CV 1/3] END learning_rate=0.12575, max_depth=5, n_estimators=300;, score=-0.289 total time= 3.1min\n",
      "[CV 2/3] END learning_rate=0.37525, max_depth=None, n_estimators=300;, score=-0.282 total time= 3.6min\n",
      "[CV 2/3] END learning_rate=0.5, max_depth=2, n_estimators=300;, score=-0.292 total time= 1.3min\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.370 total time=   6.4s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=5.0, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   3.5s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=5, min_samples_split=2;, score=-2.400 total time=   2.9s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=5, min_samples_split=20;, score=-1.708 total time=   2.9s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=20, min_samples_split=5;, score=-0.748 total time=   2.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=1, min_samples_split=10;, score=-0.400 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=5, min_samples_split=20;, score=-0.400 total time=   0.9s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=20, min_samples_split=10;, score=-0.399 total time=   0.8s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=5, min_samples_split=2;, score=-0.389 total time=   0.9s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=10, min_samples_split=5;, score=-0.387 total time=   0.9s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=20, min_samples_split=10;, score=-0.389 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=5, min_samples_split=2;, score=-0.380 total time=   1.3s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=10, min_samples_split=10;, score=-0.380 total time=   1.4s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=1, min_samples_split=2;, score=-0.376 total time=   1.6s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=5, min_samples_split=20;, score=-0.377 total time=   1.2s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=20, min_samples_split=5;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=1, min_samples_split=10;, score=-0.374 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=5, min_samples_split=20;, score=-0.372 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=20, min_samples_split=2;, score=-0.372 total time=   1.4s\n",
      "[CV 3/3] END max_depth=None, max_features=5, n_estimators=200;, score=-0.479 total time= 1.8min\n",
      "[CV 3/3] END max_depth=None, max_features=10, n_estimators=400;, score=-0.418 total time= 5.0min\n",
      "[CV 3/3] END max_depth=None, max_features=20, n_estimators=400;, score=-0.401 total time= 8.3min\n",
      "[CV 2/3] END max_depth=4, max_features=20, n_estimators=400;, score=-0.382 total time= 1.5min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=5, n_estimators=300;, score=-0.574 total time= 3.2min\n",
      "[CV 3/3] END learning_rate=0.12575, max_depth=2, n_estimators=300;, score=-0.310 total time= 1.3min\n",
      "[CV 1/3] END learning_rate=0.2505, max_depth=2, n_estimators=200;, score=-0.303 total time=  51.6s\n",
      "[CV 3/3] END learning_rate=0.2505, max_depth=2, n_estimators=200;, score=-0.304 total time=  51.6s\n",
      "[CV 1/3] END learning_rate=0.2505, max_depth=5, n_estimators=300;, score=-0.284 total time= 3.1min\n",
      "[CV 2/3] END learning_rate=0.5, max_depth=None, n_estimators=200;, score=-0.285 total time= 2.5min\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=1, min_samples_split=5;, score=-0.387 total time=   0.9s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=5, min_samples_split=10;, score=-0.389 total time=   0.9s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=10, min_samples_split=20;, score=-0.389 total time=   0.9s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=-0.381 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=5, min_samples_split=10;, score=-0.381 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=10, min_samples_split=20;, score=-0.381 total time=   1.1s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=1, min_samples_split=5;, score=-0.376 total time=   1.3s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=5, min_samples_split=10;, score=-0.376 total time=   1.2s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=10, min_samples_split=20;, score=-0.377 total time=   1.2s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=1, min_samples_split=2;, score=-0.374 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=5, min_samples_split=5;, score=-0.374 total time=   1.4s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=10, min_samples_split=20;, score=-0.371 total time=   1.4s\n",
      "[CV 2/3] END max_depth=None, max_features=5, n_estimators=100;, score=-0.549 total time=  52.7s\n",
      "[CV 1/3] END max_depth=None, max_features=10, n_estimators=300;, score=-0.432 total time= 3.7min\n",
      "[CV 2/3] END max_depth=None, max_features=20, n_estimators=100;, score=-0.481 total time= 2.0min\n",
      "[CV 3/3] END max_depth=None, max_features=20, n_estimators=300;, score=-0.407 total time= 6.1min\n",
      "[CV 3/3] END max_depth=4, max_features=5, n_estimators=300;, score=-0.398 total time=  41.6s\n",
      "[CV 1/3] END max_depth=4, max_features=10, n_estimators=400;, score=-0.388 total time= 1.5min\n",
      "[CV 3/3] END max_depth=4, max_features=20, n_estimators=200;, score=-0.383 total time= 1.1min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=200;, score=-0.614 total time=  52.5s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=5, n_estimators=300;, score=-0.574 total time= 3.2min\n",
      "[CV 2/3] END learning_rate=0.2505, max_depth=None, n_estimators=300;, score=-0.283 total time= 3.8min\n",
      "[CV 3/3] END learning_rate=0.37525, max_depth=2, n_estimators=200;, score=-0.297 total time=  51.2s\n",
      "[CV 1/3] END learning_rate=0.37525, max_depth=5, n_estimators=300;, score=-0.282 total time= 3.1min\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=10, min_samples_split=10;, score=-0.387 total time=   1.0s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=20, min_samples_split=20;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=5, min_samples_split=5;, score=-0.380 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=10, min_samples_split=10;, score=-0.380 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=20, min_samples_split=20;, score=-0.380 total time=   1.1s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=5, min_samples_split=2;, score=-0.377 total time=   1.2s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=10, min_samples_split=10;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=20, min_samples_split=20;, score=-0.376 total time=   1.2s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=5, min_samples_split=2;, score=-0.374 total time=   1.4s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=10, min_samples_split=10;, score=-0.371 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=20, min_samples_split=20;, score=-0.372 total time=   1.1s\n",
      "[CV 3/3] END max_depth=None, max_features=10, n_estimators=100;, score=-0.521 total time= 1.2min\n",
      "[CV 2/3] END max_depth=None, max_features=10, n_estimators=300;, score=-0.439 total time= 3.7min\n",
      "[CV 3/3] END max_depth=None, max_features=20, n_estimators=100;, score=-0.474 total time= 2.0min\n",
      "[CV 1/3] END max_depth=3, max_features=5, n_estimators=100;, score=-0.407 total time=  10.9s\n",
      "[CV 2/3] END max_depth=3, max_features=5, n_estimators=100;, score=-0.406 total time=  11.1s\n",
      "[CV 3/3] END max_depth=3, max_features=5, n_estimators=100;, score=-0.408 total time=  11.3s\n",
      "[CV 1/3] END max_depth=3, max_features=5, n_estimators=200;, score=-0.408 total time=  22.0s\n",
      "[CV 2/3] END max_depth=3, max_features=5, n_estimators=200;, score=-0.407 total time=  22.1s\n",
      "[CV 3/3] END max_depth=3, max_features=5, n_estimators=200;, score=-0.408 total time=  24.4s\n",
      "[CV 1/3] END max_depth=3, max_features=5, n_estimators=400;, score=-0.407 total time=  46.3s\n",
      "[CV 2/3] END max_depth=3, max_features=10, n_estimators=200;, score=-0.399 total time=  33.8s\n",
      "[CV 1/3] END max_depth=3, max_features=10, n_estimators=400;, score=-0.398 total time= 1.1min\n",
      "[CV 2/3] END max_depth=3, max_features=15, n_estimators=400;, score=-0.394 total time= 1.4min\n",
      "[CV 3/3] END max_depth=4, max_features=5, n_estimators=200;, score=-0.399 total time=  27.5s\n",
      "[CV 3/3] END max_depth=4, max_features=10, n_estimators=100;, score=-0.388 total time=  21.0s\n",
      "[CV 1/3] END max_depth=4, max_features=10, n_estimators=300;, score=-0.389 total time= 1.0min\n",
      "[CV 2/3] END max_depth=4, max_features=15, n_estimators=400;, score=-0.384 total time= 1.7min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=300;, score=-0.583 total time= 1.3min\n",
      "[CV 3/3] END learning_rate=0.12575, max_depth=None, n_estimators=200;, score=-0.293 total time= 2.5min\n",
      "[CV 2/3] END learning_rate=0.12575, max_depth=5, n_estimators=300;, score=-0.291 total time= 3.1min\n",
      "[CV 1/3] END learning_rate=0.37525, max_depth=None, n_estimators=300;, score=-0.282 total time= 3.7min\n",
      "[CV 3/3] END learning_rate=0.5, max_depth=2, n_estimators=300;, score=-0.292 total time= 1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END max_depth=6, min_samples_leaf=10, min_samples_split=20;, score=-0.376 total time=   1.2s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=1, min_samples_split=2;, score=-0.376 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=5, min_samples_split=5;, score=-0.373 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=10, min_samples_split=10;, score=-0.374 total time=   1.4s\n",
      "[CV 1/3] END max_depth=None, max_features=5, n_estimators=100;, score=-0.533 total time=  50.9s\n",
      "[CV 2/3] END max_depth=None, max_features=10, n_estimators=200;, score=-0.461 total time= 2.5min\n",
      "[CV 1/3] END max_depth=None, max_features=15, n_estimators=300;, score=-0.415 total time= 4.9min\n",
      "[CV 3/3] END max_depth=3, max_features=5, n_estimators=300;, score=-0.407 total time=  34.7s\n",
      "[CV 1/3] END max_depth=3, max_features=10, n_estimators=100;, score=-0.398 total time=  17.5s\n",
      "[CV 3/3] END max_depth=3, max_features=10, n_estimators=100;, score=-0.399 total time=  16.6s\n",
      "[CV 3/3] END max_depth=3, max_features=10, n_estimators=200;, score=-0.398 total time=  33.4s\n",
      "[CV 2/3] END max_depth=3, max_features=10, n_estimators=400;, score=-0.398 total time= 1.1min\n",
      "[CV 1/3] END max_depth=3, max_features=20, n_estimators=100;, score=-0.392 total time=  27.7s\n",
      "[CV 2/3] END max_depth=3, max_features=20, n_estimators=200;, score=-0.391 total time=  53.5s\n",
      "[CV 3/3] END max_depth=4, max_features=5, n_estimators=100;, score=-0.397 total time=  14.1s\n",
      "[CV 1/3] END max_depth=4, max_features=5, n_estimators=400;, score=-0.397 total time=  55.3s\n",
      "[CV 3/3] END max_depth=4, max_features=10, n_estimators=400;, score=-0.389 total time= 1.4min\n",
      "[CV 1/3] END max_depth=4, max_features=20, n_estimators=400;, score=-0.382 total time= 1.5min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=-0.607 total time= 2.2min\n",
      "[CV 1/3] END learning_rate=0.12575, max_depth=2, n_estimators=200;, score=-0.316 total time=  52.9s\n",
      "[CV 2/3] END learning_rate=0.12575, max_depth=2, n_estimators=300;, score=-0.311 total time= 1.3min\n",
      "[CV 3/3] END learning_rate=0.2505, max_depth=None, n_estimators=300;, score=-0.283 total time= 3.7min\n",
      "[CV 3/3] END learning_rate=0.37525, max_depth=2, n_estimators=300;, score=-0.294 total time= 1.3min\n",
      "[CV 3/3] END learning_rate=0.5, max_depth=None, n_estimators=200;, score=-0.287 total time= 2.5min\n",
      "Log Loss:  0.5265281471518203\n",
      "Accuracy Score :  83.77%\n"
     ]
    }
   ],
   "source": [
    "model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6f188ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ac2ab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END max_depth=None, max_features=15, n_estimators=200;, score=-0.428 total time= 3.4min\n",
      "[CV 2/3] END max_depth=None, max_features=20, n_estimators=200;, score=-0.436 total time= 4.1min\n",
      "[CV 2/3] END max_depth=3, max_features=15, n_estimators=100;, score=-0.394 total time=  21.7s\n",
      "[CV 2/3] END max_depth=3, max_features=15, n_estimators=300;, score=-0.393 total time= 1.1min\n",
      "[CV 1/3] END max_depth=3, max_features=20, n_estimators=300;, score=-0.392 total time= 1.3min\n",
      "[CV 2/3] END max_depth=4, max_features=5, n_estimators=400;, score=-0.396 total time=  53.9s\n",
      "[CV 2/3] END max_depth=4, max_features=15, n_estimators=100;, score=-0.384 total time=  27.4s\n",
      "[CV 3/3] END max_depth=4, max_features=15, n_estimators=300;, score=-0.384 total time= 1.3min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=None, n_estimators=300;, score=-0.573 total time= 4.0min\n",
      "[CV 2/3] END learning_rate=0.2505, max_depth=None, n_estimators=200;, score=-0.286 total time= 2.6min\n",
      "[CV 1/3] END learning_rate=0.37525, max_depth=None, n_estimators=200;, score=-0.282 total time= 2.5min\n",
      "[CV 2/3] END learning_rate=0.37525, max_depth=5, n_estimators=300;, score=-0.282 total time= 3.0min\n",
      "Log Loss:  0.2897288565717008\n",
      "Accuracy Score :  87.94%\n",
      "[CV 2/3] END max_depth=None, max_features=15, n_estimators=200;, score=-0.443 total time= 3.2min\n",
      "[CV 3/3] END max_depth=None, max_features=20, n_estimators=200;, score=-0.433 total time= 4.1min\n",
      "[CV 3/3] END max_depth=3, max_features=15, n_estimators=100;, score=-0.394 total time=  21.1s\n",
      "[CV 3/3] END max_depth=3, max_features=15, n_estimators=300;, score=-0.394 total time= 1.1min\n",
      "[CV 1/3] END max_depth=3, max_features=20, n_estimators=400;, score=-0.392 total time= 1.8min\n",
      "[CV 2/3] END max_depth=4, max_features=10, n_estimators=400;, score=-0.387 total time= 1.4min\n",
      "[CV 2/3] END max_depth=4, max_features=20, n_estimators=100;, score=-0.382 total time=  34.9s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=None, n_estimators=200;, score=-0.606 total time= 2.6min\n",
      "[CV 2/3] END learning_rate=0.12575, max_depth=2, n_estimators=200;, score=-0.317 total time=  51.9s\n",
      "[CV 2/3] END learning_rate=0.12575, max_depth=5, n_estimators=200;, score=-0.296 total time= 2.0min\n",
      "[CV 1/3] END learning_rate=0.2505, max_depth=2, n_estimators=300;, score=-0.296 total time= 1.3min\n",
      "[CV 2/3] END learning_rate=0.37525, max_depth=None, n_estimators=200;, score=-0.285 total time= 2.4min\n",
      "[CV 3/3] END learning_rate=0.37525, max_depth=5, n_estimators=300;, score=-0.283 total time= 3.0min\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=5, min_samples_split=2;, score=-0.373 total time=   1.4s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=10, min_samples_split=5;, score=-0.372 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=20, min_samples_split=10;, score=-0.372 total time=   1.3s\n",
      "[CV 2/3] END max_depth=None, max_features=10, n_estimators=100;, score=-0.518 total time= 1.3min\n",
      "[CV 1/3] END max_depth=None, max_features=10, n_estimators=400;, score=-0.415 total time= 5.0min\n",
      "[CV 1/3] END max_depth=None, max_features=20, n_estimators=300;, score=-0.407 total time= 6.0min\n",
      "[CV 1/3] END max_depth=4, max_features=5, n_estimators=100;, score=-0.398 total time=  16.1s\n",
      "[CV 1/3] END max_depth=4, max_features=5, n_estimators=200;, score=-0.397 total time=  31.7s\n",
      "[CV 1/3] END max_depth=4, max_features=10, n_estimators=200;, score=-0.388 total time=  43.3s\n",
      "[CV 1/3] END max_depth=4, max_features=15, n_estimators=100;, score=-0.384 total time=  27.4s\n",
      "[CV 2/3] END max_depth=4, max_features=15, n_estimators=300;, score=-0.383 total time= 1.4min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=None, n_estimators=200;, score=-0.606 total time= 2.7min\n",
      "[CV 3/3] END learning_rate=0.12575, max_depth=2, n_estimators=200;, score=-0.317 total time=  52.9s\n",
      "[CV 3/3] END learning_rate=0.12575, max_depth=5, n_estimators=200;, score=-0.296 total time= 2.1min\n",
      "[CV 3/3] END learning_rate=0.2505, max_depth=2, n_estimators=300;, score=-0.299 total time= 1.3min\n",
      "[CV 3/3] END learning_rate=0.37525, max_depth=None, n_estimators=300;, score=-0.284 total time= 3.8min\n",
      "[CV 2/3] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=-0.285 total time= 1.6min\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.371 total time=   5.9s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=-3.621 total time=   3.0s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=5, min_samples_split=10;, score=-2.423 total time=   3.0s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=20, min_samples_split=10;, score=-0.720 total time=   2.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=1, min_samples_split=5;, score=-0.400 total time=   0.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=10, min_samples_split=2;, score=-0.399 total time=   0.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=20, min_samples_split=5;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=1, min_samples_split=10;, score=-0.387 total time=   0.9s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=5, min_samples_split=20;, score=-0.389 total time=   0.9s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=20, min_samples_split=5;, score=-0.387 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=1, min_samples_split=20;, score=-0.380 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=10, min_samples_split=2;, score=-0.381 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=20, min_samples_split=10;, score=-0.380 total time=   1.1s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=1, min_samples_split=20;, score=-0.376 total time=   1.2s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=10, min_samples_split=2;, score=-0.377 total time=   1.2s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=20, min_samples_split=5;, score=-0.377 total time=   1.3s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=1, min_samples_split=20;, score=-0.373 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=10, min_samples_split=2;, score=-0.374 total time=   1.4s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=20, min_samples_split=10;, score=-0.371 total time=   1.3s\n",
      "[CV 3/3] END max_depth=None, max_features=5, n_estimators=400;, score=-0.443 total time= 3.4min\n",
      "[CV 3/3] END max_depth=None, max_features=15, n_estimators=300;, score=-0.417 total time= 4.8min\n",
      "[CV 1/3] END max_depth=3, max_features=5, n_estimators=300;, score=-0.407 total time=  34.1s\n",
      "[CV 2/3] END max_depth=3, max_features=5, n_estimators=400;, score=-0.407 total time=  44.9s\n",
      "[CV 1/3] END max_depth=3, max_features=10, n_estimators=300;, score=-0.398 total time=  47.8s\n",
      "[CV 1/3] END max_depth=3, max_features=15, n_estimators=200;, score=-0.394 total time=  43.4s\n",
      "[CV 3/3] END max_depth=3, max_features=15, n_estimators=400;, score=-0.395 total time= 1.4min\n",
      "[CV 1/3] END max_depth=4, max_features=5, n_estimators=300;, score=-0.398 total time=  41.6s\n",
      "[CV 2/3] END max_depth=4, max_features=10, n_estimators=200;, score=-0.387 total time=  41.1s\n",
      "[CV 3/3] END max_depth=4, max_features=15, n_estimators=200;, score=-0.384 total time=  54.2s\n",
      "[CV 1/3] END max_depth=4, max_features=20, n_estimators=200;, score=-0.383 total time= 1.1min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=200;, score=-0.614 total time=  55.4s\n",
      "[CV 1/3] END learning_rate=0.12575, max_depth=None, n_estimators=200;, score=-0.291 total time= 2.5min\n",
      "[CV 1/3] END learning_rate=0.12575, max_depth=5, n_estimators=200;, score=-0.294 total time= 2.1min\n",
      "[CV 2/3] END learning_rate=0.2505, max_depth=2, n_estimators=300;, score=-0.299 total time= 1.3min\n",
      "[CV 3/3] END learning_rate=0.37525, max_depth=None, n_estimators=200;, score=-0.285 total time= 2.5min\n",
      "[CV 2/3] END learning_rate=0.5, max_depth=None, n_estimators=300;, score=-0.284 total time= 3.2min\n",
      "[CV 1/3] END max_depth=3, max_features=15, n_estimators=300;, score=-0.395 total time= 1.1min\n",
      "[CV 3/3] END max_depth=3, max_features=20, n_estimators=300;, score=-0.392 total time= 1.4min\n",
      "[CV 2/3] END max_depth=4, max_features=10, n_estimators=100;, score=-0.388 total time=  21.1s\n",
      "[CV 2/3] END max_depth=4, max_features=10, n_estimators=300;, score=-0.388 total time= 1.0min\n",
      "[CV 1/3] END max_depth=4, max_features=15, n_estimators=400;, score=-0.384 total time= 1.6min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=None, n_estimators=300;, score=-0.573 total time= 4.0min\n",
      "[CV 3/3] END learning_rate=0.12575, max_depth=5, n_estimators=300;, score=-0.292 total time= 3.2min\n",
      "[CV 1/3] END learning_rate=0.37525, max_depth=2, n_estimators=200;, score=-0.297 total time=  51.4s\n",
      "[CV 2/3] END learning_rate=0.37525, max_depth=2, n_estimators=300;, score=-0.295 total time= 1.3min\n",
      "[CV 1/3] END learning_rate=0.5, max_depth=None, n_estimators=300;, score=-0.283 total time= 3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 3/3] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.371 total time=   4.3s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=5, min_samples_split=2;, score=-2.322 total time=   2.9s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=5, min_samples_split=10;, score=-2.285 total time=   3.5s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=20, min_samples_split=20;, score=-0.748 total time=   2.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=5, min_samples_split=2;, score=-0.400 total time=   0.7s\n",
      "[CV 1/3] END max_depth=3, min_samples_leaf=10, min_samples_split=10;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=20, min_samples_split=20;, score=-0.399 total time=   0.7s\n",
      "[CV 3/3] END max_depth=4, min_samples_leaf=5, min_samples_split=2;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=10, min_samples_split=10;, score=-0.389 total time=   1.0s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=20, min_samples_split=20;, score=-0.387 total time=   0.9s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=5, min_samples_split=2;, score=-0.381 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=10, min_samples_split=5;, score=-0.381 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=20, min_samples_split=20;, score=-0.380 total time=   1.1s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=5, min_samples_split=2;, score=-0.376 total time=   1.2s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=10, min_samples_split=5;, score=-0.377 total time=   1.2s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=20, min_samples_split=20;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=7, min_samples_leaf=5, min_samples_split=2;, score=-0.373 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=10, min_samples_split=5;, score=-0.374 total time=   1.4s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=20, min_samples_split=20;, score=-0.371 total time=   1.2s\n",
      "[CV 1/3] END max_depth=None, max_features=10, n_estimators=100;, score=-0.503 total time= 1.2min\n",
      "[CV 3/3] END max_depth=None, max_features=10, n_estimators=300;, score=-0.430 total time= 3.8min\n",
      "[CV 1/3] END max_depth=None, max_features=20, n_estimators=200;, score=-0.420 total time= 4.0min\n",
      "[CV 2/3] END max_depth=3, max_features=10, n_estimators=100;, score=-0.397 total time=  16.8s\n",
      "[CV 1/3] END max_depth=3, max_features=10, n_estimators=200;, score=-0.398 total time=  33.0s\n",
      "[CV 3/3] END max_depth=3, max_features=10, n_estimators=300;, score=-0.399 total time=  50.7s\n",
      "[CV 1/3] END max_depth=3, max_features=15, n_estimators=400;, score=-0.395 total time= 1.4min\n",
      "[CV 2/3] END max_depth=3, max_features=20, n_estimators=400;, score=-0.392 total time= 1.8min\n",
      "[CV 2/3] END max_depth=4, max_features=15, n_estimators=200;, score=-0.384 total time=  53.7s\n",
      "[CV 3/3] END max_depth=4, max_features=20, n_estimators=100;, score=-0.383 total time=  34.4s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=None, n_estimators=200;, score=-0.606 total time= 2.7min\n",
      "[CV 1/3] END learning_rate=0.12575, max_depth=2, n_estimators=300;, score=-0.309 total time= 1.3min\n",
      "[CV 1/3] END learning_rate=0.2505, max_depth=None, n_estimators=300;, score=-0.282 total time= 3.7min\n",
      "[CV 2/3] END learning_rate=0.37525, max_depth=2, n_estimators=200;, score=-0.298 total time=  51.8s\n",
      "[CV 3/3] END learning_rate=0.37525, max_depth=5, n_estimators=200;, score=-0.286 total time= 2.1min\n",
      "[CV 1/3] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=-0.284 total time= 1.9min\n",
      "[CV 1/3] END max_depth=None, max_features=15, n_estimators=400;, score=-0.405 total time= 6.6min\n",
      "[CV 3/3] END max_depth=3, max_features=10, n_estimators=400;, score=-0.399 total time= 1.1min\n",
      "[CV 1/3] END max_depth=3, max_features=20, n_estimators=200;, score=-0.392 total time=  55.1s\n",
      "[CV 3/3] END max_depth=3, max_features=20, n_estimators=400;, score=-0.392 total time= 1.8min\n",
      "[CV 1/3] END max_depth=4, max_features=15, n_estimators=200;, score=-0.384 total time=  55.1s\n",
      "[CV 2/3] END max_depth=4, max_features=20, n_estimators=200;, score=-0.382 total time=  56.5s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=None, n_estimators=300;, score=-0.573 total time= 4.0min\n",
      "[CV 3/3] END learning_rate=0.2505, max_depth=None, n_estimators=200;, score=-0.287 total time= 2.5min\n",
      "[CV 2/3] END learning_rate=0.2505, max_depth=5, n_estimators=300;, score=-0.285 total time= 3.0min\n",
      "[CV 3/3] END learning_rate=0.5, max_depth=None, n_estimators=300;, score=-0.286 total time= 3.1min\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.371 total time=   6.2s\n",
      "[CV 2/3] END C=4.445555555555556, l1_ratio=1.0, penalty=None;, score=-0.371 total time=   5.9s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.371 total time=   6.3s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/3] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.371 total time=   6.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.371 total time=   6.0s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=-5.349 total time=   3.0s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=5, min_samples_split=5;, score=-2.419 total time=   2.9s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=10, min_samples_split=20;, score=-1.326 total time=   2.9s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=1, min_samples_split=20;, score=-0.399 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=10, min_samples_split=2;, score=-0.400 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=20, min_samples_split=5;, score=-0.400 total time=   0.7s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=1, min_samples_split=20;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=10, min_samples_split=2;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=20, min_samples_split=5;, score=-0.389 total time=   0.9s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=-0.380 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=5, min_samples_split=20;, score=-0.381 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, min_samples_leaf=20, min_samples_split=5;, score=-0.380 total time=   1.1s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=1, min_samples_split=10;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=5, min_samples_split=20;, score=-0.376 total time=   1.2s\n",
      "[CV 3/3] END max_depth=6, min_samples_leaf=20, min_samples_split=2;, score=-0.377 total time=   1.2s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=1, min_samples_split=10;, score=-0.375 total time=   1.4s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=5, min_samples_split=20;, score=-0.373 total time=   1.4s\n",
      "[CV 1/3] END max_depth=7, min_samples_leaf=20, min_samples_split=2;, score=-0.371 total time=   1.4s\n",
      "[CV 2/3] END max_depth=None, max_features=5, n_estimators=200;, score=-0.480 total time= 1.7min\n",
      "[CV 2/3] END max_depth=None, max_features=10, n_estimators=400;, score=-0.422 total time= 5.0min\n",
      "[CV 2/3] END max_depth=None, max_features=20, n_estimators=400;, score=-0.400 total time= 8.2min\n",
      "[CV 1/3] END max_depth=4, max_features=20, n_estimators=300;, score=-0.383 total time= 1.4min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=-0.607 total time= 2.2min\n",
      "[CV 3/3] END learning_rate=0.12575, max_depth=None, n_estimators=300;, score=-0.289 total time= 3.7min\n",
      "[CV 2/3] END learning_rate=0.2505, max_depth=5, n_estimators=200;, score=-0.289 total time= 2.2min\n",
      "[CV 2/3] END learning_rate=0.37525, max_depth=5, n_estimators=200;, score=-0.285 total time= 2.1min\n",
      "[CV 2/3] END learning_rate=0.5, max_depth=2, n_estimators=200;, score=-0.296 total time=  51.5s\n",
      "[CV 3/3] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=-0.286 total time= 1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.370 total time=   6.1s\n",
      "[CV 3/3] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=-5.420 total time=   3.0s\n",
      "[CV 2/3] END max_depth=None, min_samples_leaf=5, min_samples_split=20;, score=-1.631 total time=   2.9s\n",
      "[CV 1/3] END max_depth=None, min_samples_leaf=20, min_samples_split=5;, score=-0.719 total time=   2.6s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=1, min_samples_split=2;, score=-0.399 total time=   0.7s\n",
      "[CV 2/3] END max_depth=3, min_samples_leaf=5, min_samples_split=10;, score=-0.399 total time=   0.7s\n",
      "[CV 3/3] END max_depth=3, min_samples_leaf=10, min_samples_split=20;, score=-0.400 total time=   0.7s\n",
      "[CV 1/3] END max_depth=4, min_samples_leaf=1, min_samples_split=5;, score=-0.389 total time=   0.9s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=5, min_samples_split=10;, score=-0.387 total time=   0.9s\n",
      "[CV 2/3] END max_depth=4, min_samples_leaf=20, min_samples_split=2;, score=-0.387 total time=   0.9s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=-0.381 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, min_samples_leaf=5, min_samples_split=10;, score=-0.380 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, min_samples_leaf=20, min_samples_split=2;, score=-0.381 total time=   1.1s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=1, min_samples_split=10;, score=-0.376 total time=   1.3s\n",
      "[CV 1/3] END max_depth=6, min_samples_leaf=5, min_samples_split=20;, score=-0.376 total time=   1.2s\n",
      "[CV 2/3] END max_depth=6, min_samples_leaf=20, min_samples_split=2;, score=-0.376 total time=   1.2s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=1, min_samples_split=5;, score=-0.375 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=5, min_samples_split=10;, score=-0.374 total time=   1.4s\n",
      "[CV 3/3] END max_depth=7, min_samples_leaf=10, min_samples_split=20;, score=-0.374 total time=   1.4s\n",
      "[CV 1/3] END max_depth=None, max_features=5, n_estimators=200;, score=-0.478 total time= 1.8min\n",
      "[CV 1/3] END max_depth=None, max_features=15, n_estimators=100;, score=-0.479 total time= 1.6min\n",
      "[CV 2/3] END max_depth=None, max_features=15, n_estimators=300;, score=-0.423 total time= 4.9min\n",
      "[CV 2/3] END max_depth=3, max_features=5, n_estimators=300;, score=-0.407 total time=  34.5s\n",
      "[CV 3/3] END max_depth=3, max_features=5, n_estimators=400;, score=-0.407 total time=  44.8s\n",
      "[CV 2/3] END max_depth=3, max_features=10, n_estimators=300;, score=-0.398 total time=  48.7s\n",
      "[CV 2/3] END max_depth=3, max_features=15, n_estimators=200;, score=-0.393 total time=  42.1s\n",
      "[CV 2/3] END max_depth=3, max_features=20, n_estimators=100;, score=-0.392 total time=  26.9s\n",
      "[CV 3/3] END max_depth=3, max_features=20, n_estimators=200;, score=-0.392 total time=  54.8s\n",
      "[CV 2/3] END max_depth=4, max_features=5, n_estimators=200;, score=-0.397 total time=  27.9s\n",
      "[CV 1/3] END max_depth=4, max_features=10, n_estimators=100;, score=-0.389 total time=  20.2s\n",
      "[CV 3/3] END max_depth=4, max_features=10, n_estimators=200;, score=-0.389 total time=  41.0s\n",
      "[CV 1/3] END max_depth=4, max_features=15, n_estimators=300;, score=-0.385 total time= 1.4min\n",
      "[CV 3/3] END max_depth=4, max_features=20, n_estimators=400;, score=-0.383 total time= 1.3min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=-0.607 total time= 2.1min\n",
      "[CV 2/3] END learning_rate=0.12575, max_depth=None, n_estimators=300;, score=-0.289 total time= 3.8min\n",
      "[CV 3/3] END learning_rate=0.2505, max_depth=5, n_estimators=200;, score=-0.289 total time= 2.1min\n",
      "[CV 1/3] END learning_rate=0.37525, max_depth=5, n_estimators=200;, score=-0.284 total time= 2.1min\n",
      "[CV 3/3] END learning_rate=0.5, max_depth=2, n_estimators=200;, score=-0.294 total time=  56.3s\n",
      "[CV 1/3] END learning_rate=0.5, max_depth=5, n_estimators=300;, score=-0.282 total time= 1.9min\n",
      "[CV 3/3] END max_depth=None, max_features=15, n_estimators=100;, score=-0.486 total time= 1.6min\n",
      "[CV 1/3] END max_depth=None, max_features=20, n_estimators=100;, score=-0.465 total time= 2.1min\n",
      "[CV 2/3] END max_depth=None, max_features=20, n_estimators=300;, score=-0.418 total time= 6.1min\n",
      "[CV 2/3] END max_depth=4, max_features=5, n_estimators=100;, score=-0.398 total time=  14.1s\n",
      "[CV 2/3] END max_depth=4, max_features=5, n_estimators=300;, score=-0.397 total time=  41.3s\n",
      "[CV 3/3] END max_depth=4, max_features=10, n_estimators=300;, score=-0.388 total time= 1.0min\n",
      "[CV 3/3] END max_depth=4, max_features=15, n_estimators=400;, score=-0.384 total time= 1.7min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=200;, score=-0.614 total time=  51.1s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=5, n_estimators=300;, score=-0.574 total time= 3.1min\n",
      "[CV 1/3] END learning_rate=0.2505, max_depth=None, n_estimators=200;, score=-0.285 total time= 2.5min\n",
      "[CV 3/3] END learning_rate=0.2505, max_depth=5, n_estimators=300;, score=-0.286 total time= 3.0min\n",
      "[CV 1/3] END learning_rate=0.5, max_depth=2, n_estimators=200;, score=-0.293 total time=  50.7s\n",
      "[CV 1/3] END learning_rate=0.5, max_depth=2, n_estimators=300;, score=-0.290 total time= 1.3min\n",
      "[CV 2/3] END learning_rate=0.5, max_depth=5, n_estimators=300;, score=-0.283 total time= 1.5min\n",
      "[CV 1/3] END max_depth=None, max_features=20, n_estimators=400;, score=-0.401 total time= 8.2min\n",
      "[CV 2/3] END max_depth=4, max_features=20, n_estimators=300;, score=-0.382 total time= 1.3min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=300;, score=-0.583 total time= 1.3min\n",
      "[CV 1/3] END learning_rate=0.12575, max_depth=None, n_estimators=300;, score=-0.287 total time= 3.7min\n",
      "[CV 2/3] END learning_rate=0.2505, max_depth=2, n_estimators=200;, score=-0.305 total time=  51.2s\n",
      "[CV 1/3] END learning_rate=0.2505, max_depth=5, n_estimators=200;, score=-0.287 total time= 2.1min\n",
      "[CV 1/3] END learning_rate=0.37525, max_depth=2, n_estimators=300;, score=-0.293 total time= 1.3min\n",
      "[CV 1/3] END learning_rate=0.5, max_depth=None, n_estimators=200;, score=-0.284 total time= 2.5min\n",
      "[CV 3/3] END learning_rate=0.5, max_depth=5, n_estimators=300;, score=-0.284 total time= 1.6min\n"
     ]
    }
   ],
   "source": [
    "model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tune = XGBClassifier(learning_rate= 0.12575, max_depth= None, n_estimators= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(xgb_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(classifier):\n",
    "    classifier.fit(x, y)\n",
    "    prediction=classifier.predict(test_x)\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    print(\"Accuracy Score : \",'{0:.2%}'.format(accuracy_score(test_y,prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46989033",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78773a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80618441",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc9641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
